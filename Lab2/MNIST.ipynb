{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89BLfDFaxo8v"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIXED HYPERPARAMETERS (MNIST)\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "learning_rate = 0.0002\n",
        "save_interval = 5\n"
      ],
      "metadata": {
        "id": "PWwfzrYwxqHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"generated_samples\", exist_ok=True)\n",
        "os.makedirs(\"final_generated_images\", exist_ok=True)"
      ],
      "metadata": {
        "id": "P9yU5gRKxsKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD DATA (MNIST)\n",
        "(x_train, _), (_, _) = keras.datasets.mnist.load_data()\n",
        "\n",
        "\n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_train = (x_train - 127.5) / 127.5\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "train_dataset = train_dataset.shuffle(60000).batch(batch_size)\n",
        "\n",
        "\n",
        "img_shape = (28, 28, 1)"
      ],
      "metadata": {
        "id": "y9I0C3kOxujo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== GENERATOR =====================\n",
        "def build_generator():\n",
        "  model = keras.Sequential([\n",
        "                layers.Dense(7 * 7 * 256, use_bias=False, input_shape=(noise_dim,)),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.LeakyReLU(0.2),\n",
        "                layers.Reshape((7, 7, 256)),\n",
        "                layers.Conv2DTranspose(128, 5, strides=1, padding=\"same\", use_bias=False),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.LeakyReLU(0.2),\n",
        "                layers.Conv2DTranspose(64, 5, strides=2, padding=\"same\", use_bias=False),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.LeakyReLU(0.2),\n",
        "                layers.Conv2DTranspose(1, 5, strides=2, padding=\"same\", use_bias=False, activation=\"tanh\")\n",
        "                ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "m1p-5FsexxhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== DISCRIMINATOR =====================\n",
        "def build_discriminator():\n",
        "  model = keras.Sequential([\n",
        "            layers.Conv2D(64, 5, strides=2, padding=\"same\", input_shape=img_shape),\n",
        "            layers.LeakyReLU(0.2),\n",
        "            layers.Dropout(0.3),\n",
        "            layers.Conv2D(128, 5, strides=2, padding=\"same\"),\n",
        "            layers.LeakyReLU(0.2),\n",
        "            layers.Dropout(0.3),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(1)\n",
        "            ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "WAIiY0zsx0at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== MODELS =====================\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "\n",
        "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "OfSvbLYOx2-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== LOSSES =====================\n",
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  return real_loss + fake_loss"
      ],
      "metadata": {
        "id": "YstVzw9cx6Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== OPTIMIZERS =====================\n",
        "gen_optimizer = keras.optimizers.Adam(learning_rate, beta_1=0.5)\n",
        "disc_optimizer = keras.optimizers.Adam(learning_rate, beta_1=0.5)"
      ],
      "metadata": {
        "id": "HPDwJec9x8uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== TRAIN STEP =====================\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "  noise = tf.random.normal([batch_size, noise_dim])\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(noise, training=True)\n",
        "    real_output = discriminator(images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "  gradients_gen = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  gradients_disc = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "  gen_optimizer.apply_gradients(zip(gradients_gen, generator.trainable_variables))\n",
        "  disc_optimizer.apply_gradients(zip(gradients_disc, discriminator.trainable_variables))\n",
        "  return gen_loss, disc_loss"
      ],
      "metadata": {
        "id": "BYD75WwKx_KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== SAVE IMAGES =====================\n",
        "def save_images(epoch):\n",
        "    noise = tf.random.normal([25, noise_dim])\n",
        "    generated_images = generator(noise, training=False)\n",
        "    generated_images = (generated_images + 1) / 2.0\n",
        "    fig = plt.figure(figsize=(5, 5))\n",
        "    for i in range(25):\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        plt.imshow(generated_images[i, :, :, 0], cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.savefig(f\"generated_samples/epoch_{epoch:02d}.png\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "Rz6nL6VsyECh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== TRAINING LOOP =====================\n",
        "for epoch in range(1, epochs + 1):\n",
        "  for image_batch in train_dataset:\n",
        "    g_loss, d_loss = train_step(image_batch)\n",
        "  print(f\"Epoch {epoch}/{epochs} | D_loss: {d_loss:.2f} | G_loss: {g_loss:.2f}\")\n",
        "  if epoch % save_interval == 0:\n",
        "    save_images(epoch)"
      ],
      "metadata": {
        "id": "3DLSUXkIyGYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== FINAL 100 IMAGES =====================\n",
        "noise = tf.random.normal([100, noise_dim])\n",
        "final_images = generator(noise, training=False)\n",
        "final_images = (final_images + 1) / 2.0\n",
        "\n",
        "\n",
        "for i in range(100):\n",
        "  plt.imshow(final_images[i, :, :, 0], cmap=\"gray\")\n",
        "  plt.axis(\"off\")\n",
        "  plt.savefig(f\"final_generated_images/img_{i}.png\")\n",
        "  plt.close()\n",
        "\n",
        "\n",
        "print(\"Training completed and images saved.\")"
      ],
      "metadata": {
        "id": "uE-ZoFkXyI5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# FINAL EVALUATION & ANALYSIS\n",
        "# ======================================================\n",
        "\n",
        "\n",
        "from scipy import linalg\n",
        "\n",
        "def get_inception_model():\n",
        "  return keras.applications.InceptionV3(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='avg',\n",
        "    input_shape=(299, 299, 3)\n",
        ")"
      ],
      "metadata": {
        "id": "kBL2vyCSyL67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Preprocessing for Inception ----------\n",
        "def preprocess_for_inception(images):\n",
        "  images = (images + 1.0) / 2.0 # [-1,1] -> [0,1]\n",
        "  images = tf.image.resize(images, (299, 299))\n",
        "  images = tf.repeat(images, 3, axis=-1)\n",
        "  images = keras.applications.inception_v3.preprocess_input(images * 255.0)\n",
        "  return images"
      ],
      "metadata": {
        "id": "beZJhaZnyOcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_inception_score(images, model, splits=10):\n",
        "    preds = model.predict(\n",
        "        preprocess_for_inception(images),\n",
        "        batch_size=32,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    split_scores = []\n",
        "\n",
        "    for i in range(splits):\n",
        "        part = preds[i * (len(preds)//splits):(i+1) * (len(preds)//splits)]\n",
        "        py = np.mean(part, axis=0)\n",
        "\n",
        "        scores = []\n",
        "        for pyx in part:\n",
        "            kl = pyx * (np.log(pyx + 1e-10) - np.log(py + 1e-10))\n",
        "            scores.append(np.sum(kl))\n",
        "\n",
        "        mean_score = np.mean(scores)\n",
        "\n",
        "        # ðŸ”’ NUMERICAL STABILITY FIX (prevents overflow)\n",
        "        mean_score = np.clip(mean_score, -50, 50)\n",
        "\n",
        "        split_scores.append(np.exp(mean_score))\n",
        "\n",
        "    return np.mean(split_scores), np.std(split_scores)\n"
      ],
      "metadata": {
        "id": "5DGtBWkyyRWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating GAN using Inception Score...\")\n",
        "\n",
        "inception_model = get_inception_model()\n",
        "\n",
        "noise = tf.random.normal([1000, noise_dim])\n",
        "generated_eval = generator(noise, training=False)\n",
        "\n",
        "is_mean, is_std = calculate_inception_score(generated_eval, inception_model)\n",
        "\n",
        "print(f\"Inception Score: {is_mean:.2f} Â± {is_std:.2f}\")\n"
      ],
      "metadata": {
        "id": "WKg0Es5TyT48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- STEP 2: Generate 100 Diverse Images ----------\n",
        "print(\"Generating 100 diverse images...\")\n",
        "noise = tf.random.normal([100, noise_dim])\n",
        "generated_images = generator(noise, training=False)\n",
        "generated_images = (generated_images + 1) / 2.0"
      ],
      "metadata": {
        "id": "dntiURTBybYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i in range(100):\n",
        "  plt.subplot(10, 10, i + 1)\n",
        "  plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
        "  plt.axis('off')\n",
        "plt.suptitle(\"100 Generated MNIST Images\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"final_generated_images/100_generated.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YzshitcRydx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- STEP 3: Real vs Generated Comparison ----------\n",
        "print(\"Creating side-by-side comparison (Real vs Generated)...\")\n",
        "\n",
        "\n",
        "real_samples = (x_train[:16] + 1) / 2.0\n",
        "noise = tf.random.normal([16, noise_dim])\n",
        "generated_samples = (generator(noise, training=False) + 1) / 2.0\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12, 6))"
      ],
      "metadata": {
        "id": "AX6fMDoFygjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(16):\n",
        "  plt.subplot(4, 8, i + 1)\n",
        "  plt.imshow(real_samples[i, :, :, 0], cmap='gray')\n",
        "  plt.title('Real', fontsize=8)\n",
        "  plt.axis('off')\n",
        "\n",
        "\n",
        "for i in range(16):\n",
        "  plt.subplot(4, 8, 16 + i + 1)\n",
        "  plt.imshow(generated_samples[i, :, :, 0], cmap='gray')\n",
        "  plt.title('Generated', fontsize=8)\n",
        "  plt.axis('off')\n",
        "\n",
        "\n",
        "plt.suptitle(\"Real vs Generated MNIST Images\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"final_generated_images/real_vs_generated.png\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"Final evaluation and analysis completed.\")"
      ],
      "metadata": {
        "id": "OsTzSl21ykEc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}