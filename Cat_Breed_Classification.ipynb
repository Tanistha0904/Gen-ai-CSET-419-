{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBo4f0yLnb5-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "import numpy as np\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DATASET_PATH = \"/content/cat_dataset\"\n",
        "NUM_CLASSES = 40\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 10\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Ek6Rh6AsnlHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATASET & TRANSFORM**"
      ],
      "metadata": {
        "id": "oqI_YZWJnx1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(DATASET_PATH, transform=transform)\n",
        "class_names = dataset.classes\n"
      ],
      "metadata": {
        "id": "l17DjH9lnqVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAIN / VAL / TEST SPLIT**"
      ],
      "metadata": {
        "id": "DaubdQJen_Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_data, val_data, test_data = random_split(\n",
        "    dataset, [train_size, val_size, test_size]\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "id": "U0IfOpI-n7ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRETRAINED RESNET-50**"
      ],
      "metadata": {
        "id": "EGPF_aruoRvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "for param in resnet50.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "resnet50.fc = nn.Linear(resnet50.fc.in_features, NUM_CLASSES)\n",
        "resnet50 = resnet50.to(device)\n"
      ],
      "metadata": {
        "id": "nvjx49sMoOKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CUSTOM CNN MODEL**"
      ],
      "metadata": {
        "id": "vD7RRR7GoHhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CustomCNN, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 28 * 28, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "iPU6zvMkoCKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING FUNCTION**"
      ],
      "metadata": {
        "id": "OQr9V8KXoYDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, epochs):\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        correct = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        train_acc = correct / len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "jSTC6IvgoNCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EVALUATION FUNCTION**"
      ],
      "metadata": {
        "id": "bVrtGT4DofrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "    return correct / len(test_loader.dataset)\n"
      ],
      "metadata": {
        "id": "M3GVuUVZoa6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FEW-SHOT LEARNING (2-SHOT)**"
      ],
      "metadata": {
        "id": "XgGpRFvHonB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "few_shot_indices = []\n",
        "shots = 2\n",
        "count = {i: 0 for i in range(NUM_CLASSES)}\n",
        "\n",
        "for idx, (_, label) in enumerate(dataset):\n",
        "    if count[label] < shots:\n",
        "        few_shot_indices.append(idx)\n",
        "        count[label] += 1\n",
        "\n",
        "few_shot_dataset = Subset(dataset, few_shot_indices)\n",
        "few_shot_loader = DataLoader(few_shot_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "few_shot_model = CustomCNN(NUM_CLASSES)\n",
        "optimizer_few = optim.Adam(few_shot_model.parameters(), lr=0.0001)\n",
        "\n",
        "train_model(few_shot_model, few_shot_loader, val_loader, optimizer_few, epochs=5)\n"
      ],
      "metadata": {
        "id": "mPOCCfSfojPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ZERO-SHOT LEARNING**"
      ],
      "metadata": {
        "id": "EYOB7QYaoyOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "from PIL import Image\n",
        "\n",
        "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "text_inputs = torch.cat([\n",
        "    clip.tokenize(f\"a photo of a {cls}\") for cls in class_names\n",
        "]).to(device)\n",
        "\n",
        "clip_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = torch.stack([\n",
        "            preprocess(transforms.ToPILImage()(img)) for img in images\n",
        "        ]).to(device)\n",
        "\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        image_features = clip_model.encode_image(images)\n",
        "        text_features = clip_model.encode_text(text_inputs)\n",
        "\n",
        "        similarity = image_features @ text_features.T\n",
        "        preds = similarity.argmax(dim=1)\n",
        "\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "zero_shot_accuracy = correct / total\n"
      ],
      "metadata": {
        "id": "L1wwsaHno5Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CONTINUAL LEARNING**"
      ],
      "metadata": {
        "id": "GSJ7uykSpBmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "half = len(dataset) // 2\n",
        "part1 = Subset(dataset, range(half))\n",
        "part2 = Subset(dataset, range(half, len(dataset)))\n",
        "\n",
        "loader1 = DataLoader(part1, batch_size=8, shuffle=True)\n",
        "loader2 = DataLoader(part2, batch_size=8, shuffle=True)\n",
        "\n",
        "continual_model = CustomCNN(NUM_CLASSES)\n",
        "optimizer_cont = optim.Adam(continual_model.parameters(), lr=0.0001)\n",
        "\n",
        "train_model(continual_model, loader1, val_loader, optimizer_cont, epochs=5)\n",
        "train_model(continual_model, loader2, val_loader, optimizer_cont, epochs=5)\n"
      ],
      "metadata": {
        "id": "qR9nLFX0o6Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FINAL COMPARISON**"
      ],
      "metadata": {
        "id": "NYlZowBxpIqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "custom_model = CustomCNN(NUM_CLASSES)\n",
        "optimizer_custom = optim.Adam(custom_model.parameters(), lr=0.0001)\n",
        "\n",
        "train_model(custom_model, train_loader, val_loader, optimizer_custom, EPOCHS)\n",
        "custom_acc = evaluate_model(custom_model, test_loader)\n",
        "\n",
        "optimizer_resnet = optim.Adam(resnet50.fc.parameters(), lr=0.0001)\n",
        "train_model(resnet50, train_loader, val_loader, optimizer_resnet, EPOCHS)\n",
        "resnet_acc = evaluate_model(resnet50, test_loader)\n",
        "\n",
        "print(\"Custom CNN Accuracy  :\", custom_acc)\n",
        "print(\"ResNet-50 Accuracy   :\", resnet_acc)\n",
        "print(\"Zero-Shot Accuracy   :\", zero_shot_accuracy)\n"
      ],
      "metadata": {
        "id": "_TXXO7jTpGCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The custom CNN trained from scratch on the cat breed dataset achieved a supervised classification accuracy of 14.62%, reflecting the challenge of learning from a limited number of samples per class. Under a few-shot learning setting, the model showed a substantial improvement, achieving 82.5% accuracy, demonstrating effective learning from a small number of representative examples.\n",
        "\n",
        "##### In the zero-shot learning scenario, implemented using a pre-trained CLIP model, an accuracy of 41.3% was achieved, indicating the ability of semantic imageâ€“text alignment to generalize to unseen classes. For continual learning, where the custom CNN was trained incrementally on different class subsets, an average accuracy of 12.8% was obtained, highlighting the impact of catastrophic forgetting."
      ],
      "metadata": {
        "id": "Jiszlj2kqZvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hzhvwRtyqhgw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PdKJ1tOoqZQL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}